<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Hadoop, BlogLee">
    <meta name="description" content="Hadoop一、Hadoop概述1.1 Hadoop 是什么1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构。 
2）主要解决，海量数据的存储和海量数据的分析计算问题。 
3）广义上来说，Hadoop通常是指一个更广泛的">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Hadoop | BlogLee</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="BlogLee" type="application/atom+xml">
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">BlogLee</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Concat</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">BlogLee</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Concat
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/19.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Hadoop</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/hadoop/">
                                <span class="chip bg-color">hadoop</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-03-03
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    40 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="一、Hadoop概述"><a href="#一、Hadoop概述" class="headerlink" title="一、Hadoop概述"></a>一、Hadoop概述</h2><h3 id="1-1-Hadoop-是什么"><a href="#1-1-Hadoop-是什么" class="headerlink" title="1.1 Hadoop 是什么"></a><strong>1.1 Hadoop</strong> <strong>是什么</strong></h3><p>1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构。 </p>
<p>2）主要解决，海量数据的存储和海量数据的分析计算问题。 </p>
<p>3）广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。</p>
<h3 id="1-2-Hadoop-发展历史（了解）"><a href="#1-2-Hadoop-发展历史（了解）" class="headerlink" title="1.2 Hadoop 发展历史（了解）"></a><strong>1.2 Hadoop</strong> <strong>发展历史（了解）</strong></h3><p>1）Hadoop创始人Doug Cutting，为 了实 现与Google类似的全文搜索功能，他在Lucene框架基础上进行优化升级，查询引擎和索引引擎。</p>
<p>2）2001年年底Lucene成为Apache基金会的一个子项目。 </p>
<p>3）对于海量数据的场景，Lucene框 架面 对与Google同样的困难，<strong>存 储海量数据困难，检 索海 量速度慢</strong>。 </p>
<p>4）学习和模仿Google解决这些问题的办法 ：微型版Nutch。 </p>
<p>5）可以说Google是Hadoop的思想之源（Google在大数据方面的三篇论文）</p>
<p><strong>GFS —&gt;HDFS</strong></p>
<p><strong>Map-Reduce —&gt;MR</strong></p>
<p><strong>BigTable —&gt;HBase</strong></p>
<p>6）2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了<strong>2年业余时间</strong>实现了DFS和MapReduce机制，使Nutch性能飙升。</p>
<p>7）2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。 </p>
<p>8）2006 年 3 月份，Map-Reduce和Nutch Distributed File System （NDFS）分别被纳入到 Hadoop 项目</p>
<p>中，Hadoop就此正式诞生，标志着大数据时代来临。 </p>
<p>9）名字来源于Doug Cutting儿子的玩具大象</p>
<h3 id="1-3-Hadoop-三大发行版本（了解）"><a href="#1-3-Hadoop-三大发行版本（了解）" class="headerlink" title="1.3 Hadoop 三大发行版本（了解）"></a><strong>1.3 Hadoop</strong> <strong>三大发行版本（了解）</strong></h3><p>Hadoop 三大发行版本：<strong>Apache、Cloudera、Hortonworks。</strong></p>
<ul>
<li><p>Apache 版本最原始（最基础）的版本，对于入门学习最好。2006</p>
<ul>
<li>官网地址：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/releases.html">https://hadoop.apache.org/releases.html</a></li>
</ul>
</li>
<li><p>Cloudera 内部集成了很多大数据框架，对应产品 CDH。2008</p>
<ul>
<li><p>官网地址：<a target="_blank" rel="noopener" href="https://www.cloudera.com/downloads/cdh">https://www.cloudera.com/downloads/cdh</a></p>
</li>
<li><p>下载地址：<a target="_blank" rel="noopener" href="https://docs.cloudera.com/documentation/enterprise/6/release">https://docs.cloudera.com/documentation/enterprise/6/release</a></p>
<p>notes/topics/rg_cdh_6_download.html</p>
</li>
</ul>
</li>
<li><p>Hortonworks 文档较好，对应产品 HDP。</p>
<ul>
<li>官网地址：<a target="_blank" rel="noopener" href="https://hortonworks.com/products/data-center/hdp/">https://hortonworks.com/products/data-center/hdp/</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="https://hortonworks.com/downloads/#data-platform">https://hortonworks.com/downloads/#data-platform</a></li>
</ul>
</li>
</ul>
<p>2011年，Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。 </p>
<h3 id="1-4-Hadoop-优势（4-高）"><a href="#1-4-Hadoop-优势（4-高）" class="headerlink" title="1.4 Hadoop **优势（4 **高）"></a><strong>1.4 Hadoop</strong> **优势（4 **高）</h3><ul>
<li>1）高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。 </li>
<li>2）高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。</li>
<li>3）高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</li>
<li>4）高容错性：能够自动将失败的任务重新分配</li>
</ul>
<p><strong>1.5 Hadoop</strong> <strong>组成（面试重点）</strong></p>
<p>在 Hadoop1.x 时 代 ，Hadoop中 的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大。 <strong>在Hadoop2.x时 代，增加 了Yarn</strong>。<strong>Yarn只负责资 源 的 调 度</strong>，<strong>MapReduce</strong> <strong>只负责运算</strong>。Hadoop3.x在组成上没有变化。</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151238246.png" alt="image-20220912151238246"></p>
<h3 id="1-5-1-HDFS-架构概述"><a href="#1-5-1-HDFS-架构概述" class="headerlink" title="1.5.1 HDFS 架构概述"></a><strong>1.5.1 HDFS</strong> <strong>架构概述</strong></h3><p>Hadoop Distributed File System，简称 <strong>HDFS</strong>，是一个<strong>分布式文件系统。</strong></p>
<p>1）NameNode（nn）：存储文件的<strong>元数据</strong>，如<strong>文件名，文件目录结构，文件属性</strong>（生成时间、副本数、</p>
<p>文件权限），以及每个文件的<strong>块列表</strong>和<strong>块所在的DataNode</strong>等。 </p>
<p>2）DataNode(dn)：在本地文件系统<strong>存储文件块数据</strong>，以及<strong>块数据的校验和</strong></p>
<p>3）Secondary NameNode(2nn)：<strong>每隔一段时间对NameNode元数据备份</strong>。 </p>
<h3 id="1-5-2-YARN-架构概述"><a href="#1-5-2-YARN-架构概述" class="headerlink" title="1.5.2 YARN 架构概述"></a><strong>1.5.2 YARN</strong> <strong>架构概述</strong></h3><p>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop 的<strong>资源管理器。</strong></p>
<p>1）ResourceManager（RM）：整个集群资源（内存、CPU等）的老大</p>
<p>3）ApplicationMaster（AM）：单个任务运行的老大</p>
<p>2）NodeManager（N M）：单个节点服务器资源老大</p>
<p>4）Container：容器，相当一台独立的服务器，里面封装了</p>
<p>任务运行所需要的资源，如<strong>内存、CPU、磁盘、网络</strong>等。</p>
<p><strong>1.5.3 MapReduce</strong> <strong>架构概述</strong></p>
<p>MapReduce 将计算过程分为两个阶段：Map 和 Reduce</p>
<p>1）Map 阶段并行处理输入数据</p>
<p>2）Reduce 阶段对 Map 结果进行汇总</p>
<p><strong>1.5.4 HDFS</strong>、<strong>YARN</strong>、<strong>MapReduce</strong> <strong>三者关系</strong></p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151310674.png" alt="image-20220912151310674"></p>
<p><strong>1.6</strong> <strong>大数据技术生态体系</strong></p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151341304.png" alt="image-20220912151341304"></p>
<p>1）Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive 与传统的数据库（MySQL）</p>
<p>间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进</p>
<p>到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。</p>
<p>2）Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，</p>
<p>Flume 支持在日志系统中定制各类数据发送方，用于收集数据；</p>
<p>3）Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统；</p>
<p>4）Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数</p>
<p>据进行计算。</p>
<p>5）Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</p>
<p>6）Oozie：Oozie 是一个管理 Hadoop 作业（job）的工作流程调度管理系统。</p>
<p>7）Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，</p>
<p>它是一个适合于非结构化数据存储的数据库。</p>
<p>8）Hive：Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张</p>
<p>数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运</p>
<p>行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开</p>
<p>发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</p>
<p>9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、</p>
<p>名字服务、分布式同步、组服务等。</p>
<h2 id="二、Hadoop-运行环境搭建（开发重点）"><a href="#二、Hadoop-运行环境搭建（开发重点）" class="headerlink" title="二、Hadoop 运行环境搭建（开发重点）"></a>二、<strong>Hadoop</strong> <strong>运行环境搭建（开发重点）</strong></h2><h3 id="安装虚拟机"><a href="#安装虚拟机" class="headerlink" title="安装虚拟机"></a>安装虚拟机</h3><p>配置IP地址，后点击NAT设置，设置网关</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151436237.png" alt="image-20220912151436237"></p>
<p>网关配置：</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151507920.png" alt="image-20220912151507920"></p>
<p>win下配置</p>
<p>打开网络，点击以太网，找到VMnet8,右击，点击属性，找到Internet协议版本4（TPC/IPv4），双击，然后配置如下</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151539232.png" alt="image-20220912151539232"></p>
<p>在虚拟机中修改网络配置如来</p>
<p>命令： vim /etc/sysconfig/network-scripts/ifcfg-ens33</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">TYPE="Ethernet"
BROWSER_ONLY="no"
BOOTPROTO="static"  #设置为静态的
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="10874839-6b8b-4d2b-bf79-d073da11636a"
DEVICE="ens33"
ONBOOT="yes"

#配置IP地址
IPADDR=192.168.10.100

#配置网关
GATEWAY=192.168.10.2

#域名解析器
DNS1=192.168.10.2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>修改主机名称：vim /etc/hostname</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop100
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p>主机名称映射</p>
<p>vim /etc/hosts</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>完成以上步骤使用命令：reboot重启虚拟机</p>
<p>使用命令<code>ifconfig</code>查看IP地址是否与自己配的一致</p>
<p>使用<code>hostname</code>命令查看主机名是否修改成功</p>
<p>最后使用<code>ping www.baidu.com</code>，ping外网查看是否ping通，ping通则说明配置没有问题</p>
<p><strong>修改windows的主机映射文件（hosts文件）</strong></p>
<p>如果操作系统是window10，先拷贝出来，修改保存以后，再覆盖即可</p>
<p>（a）进入C:\Windows\System32\drivers\etc路径</p>
<p>（b）拷贝hosts文件到桌面</p>
<p>（c）打开桌面hosts文件并添加如下内容</p>
<pre class="line-numbers language-none"><code class="language-none">192.168.10.100 hadoop100

192.168.10.101 hadoop101

192.168.10.102 hadoop102

192.168.10.103 hadoop103

192.168.10.104 hadoop104

192.168.10.105 hadoop105

192.168.10.106 hadoop106

192.168.10.107 hadoop107

192.168.10.108 hadoop108<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（d）将桌面hosts文件覆盖C:\Windows\System32\drivers\etc路径hosts文件</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/ahmcwt/article/details/109578320?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9C:%5CWindows%5CSystem32%5Cdriver&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109578320.142">https://blog.csdn.net/ahmcwt/article/details/109578320?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9C:%5CWindows%5CSystem32%5Cdriver&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109578320.142</a></p>
<p><strong>安装 epel-release</strong></p>
<p>注：Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方repository 中是找不到的）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# yum install -y epel-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p>注意：如果 Linux 安装的是最小系统版，还需要安装如下工具；如果安装的是 Linux桌面标准版，需要执行如下操作</p>
<p>​		➢ net-tool：工具包集合，包含 ifconfig 等命令</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# yum install -y net-tools <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>​		➢ vim：编辑器</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# yum install -y vim<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p>关闭防火墙，关闭防火墙开机自启</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# systemctl stop firewalld

[root@hadoop100 ~]# systemctl disable firewalld.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>注意：在企业开发时，通常单个服务器的防火墙时关的，。公司整体对外会设置非常安全的防火墙</p>
<p>创建 <strong>user用户，并修改</strong>123456 <strong>用户的密码</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# useradd user

[root@hadoop100 ~]# passwd 123456<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>配置<strong>user用户具有</strong> <strong>root</strong> <strong>权限，方便后期加</strong> <strong>sudo</strong> <strong>执行</strong> <strong>root</strong> <strong>权限的命令</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop100 ~]# vim /etc/sudoers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>修改/etc/sudoers 文件，在%wheel 这行下面添加一行，如下所示：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">## Allow root to run any commands anywhere

root ALL=(ALL) ALL

## Allows people in group wheel to run all commands

%wheel ALL=(ALL) ALL

user ALL=(ALL) NOPASSWD:ALL<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>克隆虚拟机</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151617719.png" alt="image-20220912151617719"></p>
<p>克隆三太分别是：hadoop102、hadoop103、hadoop104</p>
<p>打开hadoop102，输入：<code>vim /etc/sysconfig/network-scripts/ifcfg-ens33</code></p>
<p>修改如下<code>IPADDR=192.168.10.102</code></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="static"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="10874839-6b8b-4d2b-bf79-d073da11636a"
DEVICE="ens33"
ONBOOT="yes"

IPADDR=192.168.10.102 #只需修改id即可

GATEWAY=192.168.10.2

DNS1=192.168.10.2
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>保存退出后输入命令：vim /etc/hostname</p>
<p>修改主机名为</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop102
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>同理：hadoop103、hadoop104做相应的修改即可</p>
<h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p><strong>卸载现有JDK</strong></p>
<p>注意：安装JDK前，一定确保提前删除了虚拟机自带的JDK。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">rpm -qa|grep -i java | xargs -n1 rpm -e --nodeps 

#rpm -qa 查询所安装的所有rpm软件包
#grep -i 忽略大小写
#xargs -n1 表示每次只传递一个参数
#rpm -e --nodeps 强制卸载软件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>重启虚拟机</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">reboot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在/opt目录下创建software和module两个文件夹</p>
<p><strong>用XShell传输工具将JDK导入到opt目录下面的software文件夹下面</strong></p>
<p>解压jdk：jdk-8u212-linux-x64.tar.gz文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>进入<code> /etc/profile.d</code>目录新建my_env.sh，创建该文件用于配置jdk的环境变量，文件名随意取，环境变量如下</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>最后运行<code>source /etc/profile </code>命令，jdk就可以使用了</p>
<h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p><strong>用XShell传输工具将Hadoop导入到opt目录下面的software文件夹下面</strong></p>
<p>解压：<code>tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</code></p>
<p>在<code>/etc/profile.d</code>目录，也就是之前配置jdk创建的my_env.sh中配置Hadoop的环境变量，将下面的内容放在my_env.sh中即可。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#HADOOP_HOME

export HADOOP_HOME=/opt/module/hadoop-3.1.3

export PATH=$PATH:$HADOOP_HOME/bin

export PATH=$PATH:$HADOOP_HOME/sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>最后运行命令<code> source /etc/profile</code>hadoop就安装成功了</p>
<p><strong>测试是否安装成功</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>出现版本号说明安装成功</p>
<p><strong>Hadoop</strong> <strong>目录结构</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# ll
总用量 176
drwxr-xr-x. 2 hadoop hadoop    183 9月  12 2019 bin
drwxr-xr-x. 3 hadoop hadoop     20 9月  12 2019 etc
drwxr-xr-x. 2 hadoop hadoop    106 9月  12 2019 include
drwxr-xr-x. 3 hadoop hadoop     20 9月  12 2019 lib
drwxr-xr-x. 4 hadoop hadoop    288 9月  12 2019 libexec
-rw-rw-r--. 1 hadoop hadoop 147145 9月   4 2019 LICENSE.txt
-rw-rw-r--. 1 hadoop hadoop  21867 9月   4 2019 NOTICE.txt
-rw-rw-r--. 1 hadoop hadoop   1366 9月   4 2019 README.txt
drwxr-xr-x. 3 hadoop hadoop   4096 9月  12 2019 sbin
drwxr-xr-x. 4 hadoop hadoop     31 9月  12 2019 share
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>重要目录</strong></p>
<p>（1）bin 目录：存放对 Hadoop 相关服务（hdfs，yarn，mapred）进行操作的脚本</p>
<p>（2）etc 目录：Hadoop 的配置文件目录，存放 Hadoop 的配置文件</p>
<p>（3）lib 目录：存放 Hadoop 的本地库（对数据进行压缩解压缩功能）</p>
<p>（4）sbin 目录：存放启动或停止 Hadoop 相关服务的脚本</p>
<p>（5）share 目录：存放 Hadoop 的依赖 jar 包、文档、和官方案例</p>
<h2 id="三、Hadoop的运行模式"><a href="#三、Hadoop的运行模式" class="headerlink" title="三、Hadoop的运行模式"></a>三、Hadoop的运行模式</h2><p>1）Hadoop官方网站：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
<p>2）Hadoop运行模式包括：<strong>本地模式、伪分布式模式、以及完全分布式模式。</strong></p>
<ul>
<li><strong>本地模式</strong>：单机运行，只是用来演示一下官方案例。生产环境不用。</li>
<li><strong>伪分布式模式</strong>：也是单机运行，但是具备Hadoop集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。</li>
<li><strong>完全分布式模式</strong>：多台服务器组成分布式环境。生产环境使用。</li>
</ul>
<h3 id="3-1本地运行模式"><a href="#3-1本地运行模式" class="headerlink" title="3.1本地运行模式"></a>3.1本地运行模式</h3><p>1、创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102]#cd /opt/module/hadoop-3.1.3/

[root@hadoop102 hadoop-3.1.3]# mkdir wcinput
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>2、在wcinput文件下创建一个word.txt文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# cd wcinput
[root@hadoop102 wcinput]# vim word.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>3、编辑word.txt文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 wcinput]# vim word.txt

#编辑内容如下

banana
apple
orange
Mango
plum
grapefruit
Fragrant pear

# 按esc键 然后按 :wq  保存并退出编辑模式<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>4、回到Hadoop目录/opt/module/hadoop-3.1.3</p>
<p>5、执行程序</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput ./wcoutput

#注意这里的wcoutput目录必须不存在，否则就会报错
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>6、查看结果</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]#  cat wcoutput/part-r-00000


Fragrant	1
Mango	1
apple	1
banana	1
grapefruit	1
orange	1
pear	1
plum	1
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h3 id="3-2完全分布式运行模式（重点）"><a href="#3-2完全分布式运行模式（重点）" class="headerlink" title="3.2完全分布式运行模式（重点）"></a>3.2完全分布式运行模式（重点）</h3><h4 id="3-2-1实验环境准备："><a href="#3-2-1实验环境准备：" class="headerlink" title="3.2.1实验环境准备："></a>3.2.1实验环境准备：</h4><ul>
<li>准备3台（虚拟机）客户机（关闭防火墙、静态IP、主机名称）</li>
<li>安装JDK</li>
<li>配置环境变量</li>
<li>安装Hadoop</li>
<li>配置环境变量</li>
<li>配置集群</li>
<li>单点启动</li>
<li>配置ssh</li>
<li>群起并测试集群</li>
</ul>
<h4 id="3-2-2编写集群分发脚本xsync"><a href="#3-2-2编写集群分发脚本xsync" class="headerlink" title="3.2.2编写集群分发脚本xsync"></a>3.2.2编写集群分发脚本xsync</h4><h5 id="1）scp（secure-copy）安全拷贝"><a href="#1）scp（secure-copy）安全拷贝" class="headerlink" title="1）scp（secure copy）安全拷贝"></a>1）scp（secure copy）安全拷贝</h5><p>（1）scp定义：</p>
<p>​		scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）</p>
<p>​	（2）基本语法</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">scp -r $pdir/$fname  $user@$host:$pdir/$fname

#含义：
命令  递归   要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>（3）案例实操</p>
<p>​	前提：在hadoop102、hadoop103、hadoop104都已经创建好的/opt/module、      /opt/software两个目录，并且已经把这两个目录修改为root:root</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo chown root:root -R /opt/module<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（a）在hadoop102上，将hadoop102中/opt/module/jdk1.8.0_212目录拷贝到hadoop103上。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 module]# scp -r jdk1.8.0_212/ root@hadoop103:/opt/module/


The authenticity of host 'hadoop103 (192.168.10.103)' can't be established.
ECDSA key fingerprint is SHA256:TUWHQZbwwRYUG5ECejrabRNQTFVbS4hHkCoq7pLksII.
ECDSA key fingerprint is MD5:a6:60:fb:41:f5:2d:b1:2c:ca:19:b9:e1:d2:5a:5b:6b.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'hadoop104,192.168.10.103' (ECDSA) to the list of known hosts.
root@hadoop104's password: 输入hadoop103的密码
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（b）在hadoop103上，将hadoop102中/opt/module/hadoop-3.1.3目录拷贝到hadoop103上。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 module]# scp -r root@hadoop102:/opt/module/hadoop-3.1.3 ./

The authenticity of host 'hadoop102 (192.168.10.102)' can't be established.
ECDSA key fingerprint is SHA256:TUWHQZbwwRYUG5ECejrabRNQTFVbS4hHkCoq7pLksII.
ECDSA key fingerprint is MD5:a6:60:fb:41:f5:2d:b1:2c:ca:19:b9:e1:d2:5a:5b:6b.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'hadoop102,192.168.10.102' (ECDSA) to the list of known hosts.
root@hadoop102's password: （输入hadoop102的密码）
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（c）在hadoop103上操作，将hadoop102中/opt/module目录下所有目录拷贝到hadoop104上。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 module]# scp -r root@hadoop102:/opt/module/* root@hadoop104:/opt/module

root@hadoop102's password: 输入hadoop102的密码
root@hadoop104's password: 输入hadoop104的密码
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>



<h5 id="2）rsync远程同步工具"><a href="#2）rsync远程同步工具" class="headerlink" title="2）rsync远程同步工具"></a>2）rsync远程同步工具</h5><p>​	rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>​	rsync和scp区别：</p>
<p>​		用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>
<p>（1）基本语法</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">rsync -av $pdir/$fname $user@$host:$pdir/$fname

#含义
命令  选项参数  要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>



<p>​	 选项参数说明</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
<p>（2）案例实操</p>
<p>​	（a）删除hadoop103中/opt/module/hadoop-3.1.3/wcinput  /wcoutput</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 hadoop-3.1.3]# rm -rf wcinput/ wcoutput/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>​	（b）同步hadoop102中的/opt/module/hadoop-3.1.3到hadoop103</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 module]# rsync -av hadoop-3.1.3/ root@hadoop103:/opt/module/hadoop-3.1.3/

root@hadoop103's password:输入hadoop103的密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>



<h5 id="3）xsync集群分发脚本"><a href="#3）xsync集群分发脚本" class="headerlink" title="3）xsync集群分发脚本"></a>3）xsync集群分发脚本</h5><p>（1）需求：循环复制文件到所有节点的相同目录下</p>
<p>（2）需求分析：</p>
<p>​		（a）rsync命令原始拷贝：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">rsync  -av   /opt/module  	 hadoop@hadoop103:/opt/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>​		（b）期望脚本：xsync要同步的文件名称</p>
<p>​		（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# echo $PATH

/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk1.8.0_212/bin:/opt/module/hadoop-3.1.3/bin:/opt/module/hadoop-3.1.3/sbin:/root/bin
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>（3）脚本实现</p>
<p>（a）在/home/bin目录下创建xsync文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 opt]# cd /home

[root@hadoop102 ~]# mkdir bin

[root@hadoop102 ~]# cd bin

[root@hadoop102 bin]# vim xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在该文件中编写如下代码</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi

#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送

    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（b）修改脚本 xsync 具有执行权限</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 bin]# chmod 777 xsync 
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（c）测试脚本</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# xsync bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（d）将脚本复制到/bin中，以便全局调用</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 bin]# cp xsync /bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（e）同步环境变量配置（root所有者） </p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# ./bin/xsync /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>注意：如果用了sudo，那么xsync一定要给它的路径补全。</p>
<p>让环境变量生效</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 bin]# source /etc/profile

[root@hadoop104 opt]# source /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>





<h3 id="3-2-3SSH无密登录配置"><a href="#3-2-3SSH无密登录配置" class="headerlink" title="3.2.3SSH无密登录配置"></a>3.2.3SSH无密登录配置</h3><h4 id="1）配置ssh"><a href="#1）配置ssh" class="headerlink" title="1）配置ssh"></a>1）配置ssh</h4><p>（1）基本语法</p>
<p>ssh另一台电脑的IP地址</p>
<p>（2）ssh连接时出现Host key verification failed的解决方法</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# ssh hadoop103<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<ul>
<li><p>如果出现如下内容</p>
<p>Are you sure you want to continue connecting (yes/no)? </p>
<p>输入yes，并回车</p>
</li>
</ul>
<p>（3）退回到hadoop102</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# exit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h4 id="2）无密钥配置"><a href="#2）无密钥配置" class="headerlink" title="2）无密钥配置"></a>2）无密钥配置</h4><p>（1）免密登录原理 </p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151716675.png" alt="image-20220912151716675"></p>
<p>（2）生成公钥和私钥</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 .ssh]# pwd
/root/.ssh
[root@hadoop102 .ssh]# ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p>
<p>（3）将公钥拷贝到要免密登录的目标机器上</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 .ssh]# ssh-copy-id hadoop102

[root@hadoop102 .ssh]# ssh-copy-id hadoop103

[root@hadoop102 .ssh]# ssh-copy-id hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>注意：</p>
<p>还需要在hadoop103上采用hadoop(或其他普通)账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p>
<p>还需要在hadoop104上采用hadoop（或其他普通）账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p>
<p>还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；</p>
<p>3）.ssh文件夹下（~/.ssh）的文件功能解释</p>
<table>
<thead>
<tr>
<th>known_hosts</th>
<th>记录ssh访问过计算机的公钥（public key）</th>
</tr>
</thead>
<tbody><tr>
<td>id_rsa</td>
<td>生成的私钥</td>
</tr>
<tr>
<td>id_rsa.pub</td>
<td>生成的公钥</td>
</tr>
<tr>
<td>authorized_keys</td>
<td>存放授权过的无密登录服务器公钥</td>
</tr>
</tbody></table>
<h3 id="3-2-4-集群配置"><a href="#3-2-4-集群配置" class="headerlink" title="3.2.4 集群配置"></a>3.2.4 <strong>集群配置</strong></h3><p>1）集群部署规划</p>
<p>​	注意：</p>
<p>​	NameNode和SecondaryNameNode不要安装在同一台服务器</p>
<p>​	ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNodeDataNode</td>
<td>DataNode</td>
<td>SecondaryNameNodeDataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManagerNodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p>2）配置文件说明</p>
<p>​		Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<p>（1）默认配置文件：</p>
<table>
<thead>
<tr>
<th>要获取的默认文件</th>
<th>文件存放在Hadoop的jar包中的位置</th>
</tr>
</thead>
<tbody><tr>
<td>[core-default.xml]</td>
<td>hadoop-common-3.1.3.jar/core-default.xml</td>
</tr>
<tr>
<td>[hdfs-default.xml]</td>
<td>hadoop-hdfs-3.1.3.jar/hdfs-default.xml</td>
</tr>
<tr>
<td>[yarn-default.xml]</td>
<td>hadoop-yarn-common-3.1.3.jar/yarn-default.xml</td>
</tr>
<tr>
<td>[mapred-default.xml]</td>
<td>hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml</td>
</tr>
</tbody></table>
<p>（2）自定义配置文件：</p>
<p>​	<strong>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml</strong>四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<p>3）配置集群</p>
<p>（1）核心配置文件</p>
<p>​		配置core-site.xml</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# cd $HADOOP_HOME/etc/hadoop

[root@hadoop102 hadoop]# vim core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>文件内容如下：</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>

<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

 

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

  <span class="token comment">&lt;!-- 指定NameNode的地址 --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop102:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

 

  <span class="token comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/opt/module/hadoop-3.1.3/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

 

  <span class="token comment">&lt;!-- 配置HDFS网页登录使用的静态用户为root --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（2）HDFS配置文件</p>
<p>配置hdfs-site.xml</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# vim hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>文件内容如下：</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>

<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

 

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

	<span class="token comment">&lt;!-- nn web端访问地址--&gt;</span>

	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop102:9870<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

	<span class="token comment">&lt;!-- 2nn web端访问地址--&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop104:9868<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（3）YARN配置文件</p>
<p>配置yarn-site.xml</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# vim yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>文件内容如下：</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>

<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

  <span class="token comment">&lt;!-- 指定MR走shuffle --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

 

  <span class="token comment">&lt;!-- 指定ResourceManager的地址--&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop103<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

 

  <span class="token comment">&lt;!-- 环境变量的继承 --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（4）MapReduce配置文件</p>
<p>配置mapred-site.xml</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# vim mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>文件内容如下：</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>

<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

 

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

	<span class="token comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>4）在集群上分发配置好的Hadoop配置文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# cd ..
[root@hadoop102 etc]# pwd
/opt/module/hadoop-3.1.3/etc

[root@hadoop102 etc]# xsync hadoop/

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>5）去103和104上查看文件分发情况</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml

[root@hadoop104 ~]# cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>



<h3 id="3-2-5-群起集群"><a href="#3-2-5-群起集群" class="headerlink" title="3.2.5 群起集群"></a>3.2.5 群起集群</h3><p>首先关闭防火墙</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
#查看firewall状态
systemctl status firewalld.service

#停止firewall
systemctl stop firewalld.service

#禁止firewall开机启动
systemctl disable firewalld.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>1）配置workers</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# vim /opt/module/hadoop-3.1.3/etc/hadoop/workers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在该文件中增加如下内容：(localhost删除掉)</p>
<p>hadoop102</p>
<p>hadoop103</p>
<p>hadoop104</p>
<p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p>
<p>同步所有节点配置文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# xsync workers <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>2）启动集群</p>
<p>​	（1）<strong>如果集群是第一次启动</strong>，需要在hadoop102节点格式化NameNode（注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# hdfs namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（2）启动HDFS</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# sbin/start-dfs.sh

#启动完毕使用jps命令查看
[root@hadoop102 hadoop-3.1.3]# jps
5409 Jps
5124 DataNode
4985 NameNode
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#若出现如下错误
[root@hadoop102 hadoop-3.1.3]# sbin/start-dfs.sh
Starting namenodes on [hadoop102]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [hadoop104]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.

#解决方法
在/hadoop/sbin路径下：
将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数
[root@hadoop102 hadoop-3.1.3]# cd sbin/
#!/usr/bin/env bash
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root

还有，start-yarn.sh，stop-yarn.sh顶部也需添加以下：
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
修改后重启 ./start-dfs.sh，成功！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（3）在配置了ResourceManager的节点（hadoop103）启动YARN</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#若执行上面的命令报如下错误
[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh
Starting resourcemanager
ERROR: Attempting to operate on yarn resourcemanager as root
ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.
Starting nodemanagers
ERROR: Attempting to operate on yarn nodemanager as root
ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.

#解决方法
在sbin 目录下 更改 start-yarn.sh 和 stop-yarn.sh 信息，在两个配置文件的第一行添加：
[root@hadoop103 hadoop-3.1.3]# cd sbin/
#!/usr/bin/env bash
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>（4）Web端查看HDFS的NameNode</p>
<p>（a）浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a>   ==注意：要在Hadoop102的服务器访问==</p>
<p>​		（b）查看HDFS上存储的数据信息</p>
<p>（5）Web端查看YARN的ResourceManager</p>
<p>（a）浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088</a>  ==注意：要在Hadoop103的服务器访问==</p>
<p>​	（b）查看YARN上运行的Job信息</p>
<p>3）集群基本测试</p>
<p>（1）上传文件到集群</p>
<p>​	上传小文件</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151809735.png" alt="image-20220912151809735"></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# hadoop fs -mkdir /input

#输入上面该命令再hadoop102上输入http://hadoop102:9870/explorer.html#/访问

[root@hadoop102 ~]# hadoop fs -put $HADOOP_HOME/wcinput/word.txt /input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>​	上传大文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（2）上传文件后查看文件存放在什么位置</p>
<p>​	查看HDFS文件存储路径</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 subdir0]# pwd

/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1436128598-192.168.10.102-1610603650062/current/finalized/subdir0/subdir0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>​	查看HDFS在磁盘存储文件内容</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 subdir0]# cat blk_1073741825

hadoop yarn

hadoop mapreduce 

atguigu

atguigu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（3）拼接</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-rw-rw-r--. 1 atguigu atguigu 134217728 5月 23 16:01 **blk_1073741836**

-rw-rw-r--. 1 atguigu atguigu  1048583 5月 23 16:01 blk_1073741836_1012.meta

-rw-rw-r--. 1 atguigu atguigu  63439959 5月 23 16:01 **blk_1073741837**

-rw-rw-r--. 1 atguigu atguigu   495635 5月 23 16:01 blk_1073741837_1013.meta

[root@hadoop102 subdir0]# cat blk_1073741836&gt;&gt;tmp.tar.gz

[root@hadoop102 subdir0]# cat blk_1073741837&gt;&gt;tmp.tar.gz

[root@hadoop102 subdir0]# tar -zxvf tmp.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（4）下载</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop104 software]# hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（5）执行wordcount程序</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p>==注意==：当执行wordcount程序时运行结果如下</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151837913.png" alt="image-20220912151837913"></p>
<p>这时需要在集群的yarn-site.xml中添加如下配置：</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.resource.memory-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.scheduler.minimum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>2048<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.vmem-pmem-ratio<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>2.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>同时还要在集群的 mapred-site.xml 添加以下内容</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.app.mapreduce.am.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.map.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.reduce.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>执行wordcount程序成功的运行结果如下</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151901254.png" alt="image-20220912151901254"></p>
<h3 id="3-2-6-配置历史服务器"><a href="#3-2-6-配置历史服务器" class="headerlink" title="3.2.6 配置历史服务器"></a><strong>3.2.6</strong> <strong>配置历史服务器</strong></h3><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p>
<p><strong>1</strong>）配置 mapred-site.xml</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# pwd
/opt/module/hadoop-3.1.3/etc/hadoop

[root@hadoop102 hadoop]# vim mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>在该文件里面增加如下配置。</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!-- 历史服务器端地址 --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

 	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

 	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop102:10020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 历史服务器 web 端地址 --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop102:19888<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>2</strong>）分发配置</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>3</strong>）<strong>在</strong> <strong>hadoop102</strong> <strong>启动历史服务器</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# mapred --daemon start historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>4</strong>）<strong>查看历史服务器是否启动</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# jps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>5</strong>）查看 <strong>JobHistory</strong></p>
<p><a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p>
<h3 id="3-2-7-配置日志的聚集"><a href="#3-2-7-配置日志的聚集" class="headerlink" title="3.2.7 配置日志的聚集"></a><strong>3.2.7</strong> <strong>配置日志的聚集</strong></h3><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912151927514.png" alt="image-20220912151927514"></p>
<p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
<p>==注意：开启日志聚集功能，需要重新启动 NodeManager 、ResourceManager 和HistoryServer。==</p>
<p>开启日志聚集功能具体步骤如下： </p>
<p><strong>1</strong>）<strong>配置yarn-site.xml</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# vim yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在该文件里面增加如下配置。</p>
<pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token comment">&lt;!-- 开启日志聚集功能 --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation-enable<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span> 

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log.server.url<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span> 

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>http://hadoop102:19888/jobhistory/logs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation.retain-seconds<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>604800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>2</strong>）<strong>分发配置</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop]# xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>3</strong>）关闭 <strong>NodeManager</strong> 、<strong>ResourceManager</strong> <strong>和</strong> <strong>HistoryServer</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 hadoop-3.1.3]# sbin/stop-yarn.sh

[root@hadoop103 hadoop-3.1.3]# mapred --daemon  stop historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><strong>4</strong>）启动 <strong>NodeManager</strong> 、<strong>ResourceManage和HistoryServer</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# start-yarn.sh

[root@hadoop102 ~]# mapred --daemon start historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><strong>5</strong>）<strong>删除HDFS 上已经存在的输出文件</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# hadoop fs -rm -r /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>6</strong>）<strong>执行WordCount 程序</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>7</strong>）<strong>查看日志</strong></p>
<p>（1）历史服务器地址</p>
<p>​      <a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p>
<p>  (2）历史任务列表</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152002023.png" alt="image-20220912152002023"></p>
<p>(3）查看任务运行日志</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152019031.png" alt="image-20220912152019031"></p>
<p>(4）运行日志详情</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152037104.png" alt="image-20220912152037104"></p>
<h3 id="3-2-8集群启动-x2F-停止方式总结"><a href="#3-2-8集群启动-x2F-停止方式总结" class="headerlink" title="3.2.8集群启动/停止方式总结"></a>3.2.8集群启动/停止方式总结</h3><p><strong>1）各个模块分开启动/停止</strong>（配置ssh是前提）<strong>常用</strong></p>
<p>​	（1）整体启动/停止HDFS</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">start-dfs.sh/stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>​	（2）整体启动/停止YARN</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">start-yarn.sh/stop-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>2）各个服务组件逐一启动/停止</strong></p>
<p>​	（1）分别启动/停止HDFS组件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs --daemon start/stop namenode/datanode/secondarynamenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>​	（2）启动/停止YARN</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">yarn --daemon start/stop resourcemanager/nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h3 id="3-2-9编写Hadoop集群常用脚本"><a href="#3-2-9编写Hadoop集群常用脚本" class="headerlink" title="3.2.9编写Hadoop集群常用脚本"></a><strong>3.2.9编写Hadoop集群常用脚本</strong></h3><p><strong>1）Hadoop集群启停脚本（包含HDFS，Yarn，Historyserver）：myhadoop.sh</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# cd bin

[root@hadoop102 bin]#vim myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>输入如下内容</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!/bin/bash

if [ $# -lt 1 ]

then
  echo "No Args Input..."
  exit ;
fi

case $1 in
"start")

    echo " =================== 启动 hadoop集群 ==================="

 

    echo " --------------- 启动 hdfs ---------------"

    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"

    echo " --------------- 启动 yarn ---------------"

    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"

    echo " --------------- 启动 historyserver ---------------"

    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"

;;

"stop")

    echo " =================== 关闭 hadoop集群 ==================="

 

    echo " --------------- 关闭 historyserver ---------------"

    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"

    echo " --------------- 关闭 yarn ---------------"

    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"

    echo " --------------- 关闭 hdfs ---------------"

    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"

;;

*)

  echo "Input Args Error..."

;;

esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p> 保存后退出，然后赋予脚本执行权限</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 bin]# chmod 777 myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>2）查看三台服务器Java进程脚本：jpsall</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# cd bin

[root@hadoop102 bin]# vim jpsall<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>输入如下内容</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!/bin/bash

for host in hadoop102 hadoop103 hadoop104

do

    echo =============== $host ===============

    ssh $host jps 
done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p> 保存后退出，然后赋予脚本执行权限</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 bin]# chmod 777 jpsall<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>3）分发/home/hadoop/bin目录，保证自定义脚本在三台机器上都可以使用</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# xsync bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h3 id="3-2-10-常用端口号说明"><a href="#3-2-10-常用端口号说明" class="headerlink" title="**3.2.10 **常用端口号说明"></a>**3.2.10 **常用端口号说明</h3><table>
<thead>
<tr>
<th>端口名称</th>
<th>Hadoop2.x</th>
<th>Hadoop3.x</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode内部通信端口</td>
<td>8020 / 9000</td>
<td>==8020== / 9000/9820</td>
</tr>
<tr>
<td>NameNode HTTP UI对用户后的查询端口</td>
<td>==50070==</td>
<td>==9870==</td>
</tr>
<tr>
<td>MapReduce查看执行任务端口</td>
<td>8088</td>
<td>8088</td>
</tr>
<tr>
<td>历史服务器通信端口</td>
<td>19888</td>
<td>19888</td>
</tr>
</tbody></table>
<h3 id="3-2-11-集群时间同步"><a href="#3-2-11-集群时间同步" class="headerlink" title="3.2.11 集群时间同步"></a><strong>3.2.11 集群时间同步</strong></h3><p>==如果服务器在公网环境（能连接外网），可以不采用集群时间同步==，因为服务器会定期和公网时间进行校准；</p>
<p>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。</p>
<p><strong>1）需求</strong></p>
<p>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用1分钟同步一次。</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152107115.png" alt="image-20220912152107115"></p>
<p><strong>2）时间服务器配置（必须root用户）</strong></p>
<p>（1）==查看所有节点==ntpd服务状态和开机自启动状态</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo systemctl status ntpdate.service

[root@hadoop102 ~]# sudo systemctl start ntpdate.service

[root@hadoop102 ~]# sudo systemctl is-enabled ntpdate.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（2）修改hadoop102的ntp.conf配置文件</p>
<p>注意：NTP服务先执行以下命令，要不然<code>/etc</code>目录下没有<code>ntp.conf</code>文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# yum -y install ntp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo vim /etc/ntp.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>修改内容如下</p>
<p>（a）修改1（授权192.168.==10.0==-192.168.==10.255==网段上的所有机器可以从这台机器上查询和同步时间）</p>
<p><code>\#restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</code></p>
<p>为<code>restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</code></p>
<p>​	（b）修改2（集群在局域网中，不使用其他互联网上的时间）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">server 0.centos.pool.ntp.org iburst

server 1.centos.pool.ntp.org iburst

server 2.centos.pool.ntp.org iburst

server 3.centos.pool.ntp.org iburst<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>为</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#server 0.centos.pool.ntp.org iburst

#server 1.centos.pool.ntp.org iburst

#server 2.centos.pool.ntp.org iburst

#server 3.centos.pool.ntp.org iburst<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">server 127.127.1.0

fudge 127.127.1.0 stratum 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152135781.png" alt="image-20220912152135781"></p>
<p>（3）修改hadoop102的/etc/sysconfig/ntpd 文件</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo vim /etc/sysconfig/ntpd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>增加内容如下（让硬件时间与系统时间一起同步）</p>
<pre class="line-numbers language-none"><code class="language-none">SYNC_HWCLOCK=yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（4）重新启动ntpd服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo systemctl start ntpd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（5）设置ntpd服务开机启动</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# sudo systemctl enable ntpd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>3）其他机器配置（必须root用户）</strong></p>
<p>（1）关闭所有节点上ntp服务和自启动</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# sudo systemctl stop ntpd

[root@hadoop103 ~]# sudo systemctl disable ntpd

[root@hadoop104 ~]# sudo systemctl stop ntpd

[root@hadoop104 ~]# sudo systemctl disable ntpd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>（2）在其他机器配置1分钟与时间服务器同步一次</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# sudo crontab -e<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>编写定时任务如下：</p>
<pre class="line-numbers language-none"><code class="language-none">*/1 * * * * /usr/sbin/ntpdate hadoop102<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（3）修改任意机器时间</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# sudo date -s "2021-9-11 11:11:11"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>（4）1分钟后查看机器是否与时间服务器同步</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop103 ~]# sudo date<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h1 id="常见错误及解决方案"><a href="#常见错误及解决方案" class="headerlink" title="常见错误及解决方案"></a><strong>常见错误及解决方案</strong></h1><p>1）防火墙没关闭、或者没有启动YARN</p>
<pre class="line-numbers language-none"><code class="language-none">INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>2）主机名称配置错误</p>
<p>3）IP地址配置错误</p>
<p>4）ssh没有配置好</p>
<p>5）root用户和hadoop两个用户启动集群不统一</p>
<p>6）配置文件修改不细心</p>
<p>7）不识别主机名称</p>
<p>java.net.UnknownHostException: hadoop102: hadoop102</p>
<p>​    at java.net.InetAddress.getLocalHost(InetAddress.java:1475)</p>
<p>​    at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:146)</p>
<p>​    at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)</p>
<p>​    at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)</p>
<p>​    at java.security.AccessController.doPrivileged(Native Method)</p>
<p>at javax.security.auth.Subject.doAs(Subject.java:415)</p>
<p>解决办法：</p>
<p>（1）在/etc/hosts文件中添加192.168.10.102 hadoop102</p>
<p>​	（2）主机名称不要起hadoop  hadoop000等特殊名称</p>
<p>8）DataNode和NameNode进程同时只能工作一个。</p>
<p><img src="https://raw.githubusercontent.com/rookiesnewbie/images/master/images/image-20220912152206347.png" alt="image-20220912152206347"></p>
<p>9）执行命令不生效，粘贴Word中命令时，遇到-和长–没区分开。导致命令失效</p>
<p>解决办法：尽量不要粘贴Word中代码。</p>
<p>10）jps发现进程已经没有，但是重新启动集群，提示进程已经开启。</p>
<p>原因是在Linux的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。</p>
<p>11）jps不生效</p>
<p>原因：全局变量hadoop java没有生效。解决办法：需要source /etc/profile文件。</p>
<p>12）8088端口连接不上</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">[root@hadoop102 ~]# cat /etc/hosts<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>注释掉如下代码</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#127.0.0.1  localhost localhost.localdomain localhost4 localhost4.localdomain4

#::1     hadoop102<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>






                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">BlogLee</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://rookiesnewbie.github.io/2023/03/03/hadoop/">https://rookiesnewbie.github.io/2023/03/03/hadoop/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">BlogLee</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/hadoop/">
                                    <span class="chip bg-color">hadoop</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/03/03/index/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="index">
                        
                        <span class="card-title">index</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-03-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            BlogLee
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/03/03/ji-he/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="Java集合">
                        
                        <span class="card-title">Java集合</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-03-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            BlogLee
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Java%E9%9B%86%E5%90%88/">
                        <span class="chip bg-color">Java集合</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <a href="/about" target="_blank">BlogLee</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">215k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2023";
                        var startMonth = "3";
                        var startDate = "3";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/rookiesnewbie" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:2049448867@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2049448867" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2049448867" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
